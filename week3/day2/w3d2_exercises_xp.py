# -*- coding: utf-8 -*-
"""W3D2 Exercises XP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ShMQV6VQbvZeWGGusrx-jmsboJIOCsYX

#Exercises XP

**Exercise 1: Identifying Data Types**
Below are various data sources. Identify whether each one is an example of structured or unstructured data.

A company’s financial reports stored in an Excel file.
**The data is organized in a predefined format, such as tables and rows.**

Photographs uploaded to a social media platform.
**The data is not organized in a predefined manner and can vary widely in content.**

A collection of news articles on a website.
**The articles contain text and multimedia content that is not organized in a fixed format.**

Inventory data in a relational database.
**The data is organized into tables with defined relationships, making it easily searchable and analyzable.**

Recorded interviews from a market research study.
**The audio recordings do not adhere to a structured format and contain variable content.**

#Exercise 2: Transformation Exercise

For each of the following unstructured data sources, propose a method to convert it into structured data. Explain your reasoning.

**A series of blog posts about travel experiences.**

*Method: Text Mining with Quantitative Metrics
Assign numerical values to key data points extracted from the posts, such as:
Number of posts mentioning specific locations (e.g., Paris: 15 mentions)
Average rating of experiences on a scale of 1-5 (e.g., average rating: 4.2)
Frequency of specific keywords such as "food," "adventure," etc. (e.g., "food": 10 occurrences, "adventure": 8 occurrences)
Structure the data into a table with columns: “Location,” “Post Count,” “Average Rating,” and “Keyword Frequency.”*

**Audio recordings of customer service calls.**
*Method: Transcription with Quantifiable Metrics
Implementation: Implement KPI's for customer service representative and quantify:
Number of calls categorized by issue type (e.g., billing: 30 calls, technical support: 45 calls)
Average call duration in minutes (e.g., average duration: 5.7 minutes)
Sentiment score on a scale from -1 (negative) to 1 (positive) for each call (e.g., average sentiment score: 0.3)
Create a structured dataset with columns: “Issue Type,” “Call Count,” “Average Duration (min),” and “Average Sentiment Score.”*

**Handwritten notes from a brainstorming session.**

*Method: OCR with Quantitative Analysis
Implementation: Convert notes to text and count:
Number of ideas generated (e.g., total ideas: 25)
Ideas categorized into themes (e.g., Theme A: 10 ideas, Theme B: 8 ideas)
Assign a ranking score for each idea (1-5 scale for feasibility) and average rankings (e.g., average score: 4.1)
Structure this data in a table with columns: “Theme,” “Idea Count,” “Average Ranking,” and “Total Ideas.”*

**A video tutorial on cooking.**

*Method: Video Analysis with Numerical Structuring
Implementation: Analyze the video content and quantify:
Number of ingredients listed (e.g., total ingredients: 8)
Average cooking time in minutes (e.g., average time: 30 minutes)
Number of steps in the recipe (e.g., total steps: 6)
Create a structured format with columns: “Ingredient Count,” “Average Cooking Time (min),” “Step Count,” and “Recipe Rating (scale of 1-5).”*

#Exercise 3 : Import a file from Kaggle
"""

from google.colab import files
files.upload('train')

import zipfile
import os

file_name = 'train/train.zip'
with zipfile.ZipFile(file_name, 'r') as zip_ref:
    zip_ref.extractall('train')

# List the contents of the extracted folder to verify
os.listdir('train')

import pandas as pd
train = pd.read_csv('train/train.csv')
train.head()

"""#Exercise 4: Importing a CSV File"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
 import io

iris_data_set = pd.read_csv(io.BytesIO(uploaded['Iris_dataset.csv']))
      # You can now work with 'df'

# List the contents of the extracted folder to verify
os.listdir('Iris_dataset')

iris_data_set.head()

"""#Exercise 5 : Export a dataframe to excel format and JSON format.

"""

# to export a data set to excel format:
data = {'Name': ['Alice', 'Bob', 'Charlie'],
        'Age': [25, 30, 35],
        'City': ['New York', 'Los Angeles', 'Chicago']}
data_excel = pd.DataFrame(data)

#Export to Excel
excel_filename = 'data_excel.xlsx'
data_excel.to_excel(excel_filename, index=False) # index=False prevents writing the DataFrame index to Excel

from google.colab import files
files.download(excel_filename) #this is to download the file as the name chosen

#now to export in json format
# Create a sample DataFrame (using the same one as above)
data = {'Name': ['Alice', 'Bob', 'Charlie'],
        'Age': [25, 30, 35],
        'City': ['New York', 'Los Angeles', 'Chicago']}
df_json = pd.DataFrame(data)

json_filename = 'data_json_file.json'
df_json.to_json(json_filename, orient='records', indent=4) # orient and indent control the JSON format

from google.colab import files
files.download(json_filename) #to download the json file we just exported

"""#Exercise 6: Reading JSON Data
Import the JSON data from the provided URL.
Use Pandas to read the JSON data.
Display the first five entries of the data.
"""

url = 'data.json'
data_json_df = pd.read_json('https://github.com/devtlv/Datasets-DA-Bootcamp-2-/raw/refs/heads/main/Week%204%20-%20Data%20Understanding/W4D3%20-%20Importing%20Data,%20Exporting%20D/posts.zip')

data_json_df.head()