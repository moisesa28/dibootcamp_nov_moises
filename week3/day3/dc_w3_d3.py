# -*- coding: utf-8 -*-
"""DC_W3_D3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UtG1mgr51xyUugkkKjBEnszve3aYfDsb

#Daily Challenge: Data Handling and Analysis in Python

* Normalize the ‘salary’ column using Min-Max normalization which scales all salary values between 0 and 1.

* Implement dimensionality reduction like Principal Component Analysis (PCA) or t-SNE to reduce the number of features (columns) in the dataset.

* Group the dataset by the ‘experience_level’ column and calculate the average and median salary for each experience level (e.g., Junior, Mid-level, Senior).
"""

from google.colab import files
uploaded = files.upload()

from sklearn.preprocessing import MinMaxScaler
import pandas as pd
data_salaries = pd.read_csv('datascience_salaries.csv')
data_salaries.head()

data_salaries.columns

data_salaries['salary'].isna().sum() #we check that we have all the complete data for the salary column

data_salaries['salary']

data_salaries['salary'].min() #this shows us the minimum salary from the column

data_salaries['salary'].max() #this shows us the max salary from the column

data_salaries['salary'].median() #we use the median to show what's the middle range of the salary

salaries = [30000,63000,228000]

scaler = MinMaxScaler()
data_salaries[['salary_normalized']] = scaler.fit_transform(data_salaries[['salary']])

data_salaries.head()

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 5))

# Before normalization
plt.subplot(1, 2, 1)
plt.hist(data_salaries['salary'], bins=20)
plt.title('Original Salary Distribution')

# After normalization
plt.subplot(1, 2, 2)
plt.hist(data_salaries['salary_normalized'], bins=20)
plt.title('Normalized Salary Distribution')

plt.show()

"""Prepare the Data for Dimensionality Reduction"""

from sklearn.preprocessing import StandardScaler

# Select only numeric columns for PCA / t-SNE
numeric_data_salaries = data_salaries.select_dtypes(include=['int64', 'float64'])

# Scale the data
scaler = StandardScaler()
scaled_data = scaler.fit_transform(numeric_data_salaries)

from sklearn.decomposition import PCA

pca = PCA(n_components=2)
pca_components = pca.fit_transform(scaled_data)

# Add back to DataFrame
data_salaries['PCA1'] = pca_components[:, 0]
data_salaries['PCA2'] = pca_components[:, 1]

data_salaries[['PCA1', 'PCA2']].head()

import matplotlib.pyplot as plt

plt.scatter(data_salaries['PCA1'], data_salaries['PCA2'])
plt.xlabel("Principal Component 1")
plt.ylabel("Principal Component 2")
plt.title("PCA Feature Reduction (2 Components)")
plt.show()

#Group the dataset by the ‘experience_level’

grouped_salary = data_salaries.groupby('experience_level')['salary'].agg(['mean', 'median'])

grouped_salary

grouped_salary = data_salaries.groupby('experience_level')['salary'] \
                   .agg(avg_salary='mean', median_salary='median')

grouped_salary

grouped_salary['avg_salary'].plot(kind='bar', figsize=(8,5))
grouped_salary['median_salary'].plot(kind='bar', figsize=(8,5))

experience_map = {
    'EN': 'Junior',
    'MI': 'Mid-Level',
    'SE': 'Senior',
    'EX': 'Executive'
}

data_salaries['experience_level'] = data_salaries['experience_level'].map(experience_map)