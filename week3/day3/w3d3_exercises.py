# -*- coding: utf-8 -*-
"""W3D3_Exercises.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Yhm3Lomyc_E4btLlw1C9-KBBFXmWnYTd

#Exercise 1: Duplicate Detection and Removal
Objective: Identify and remove duplicate entries in the Titanic dataset.

Load the Titanic dataset.
Identify if there are any duplicate rows based on all columns.
Remove any duplicate rows found in the dataset.
Verify the removal of duplicates by checking the number of rows before and after the duplicate removal.
"""

from google.colab import files
files.upload()

import pandas as pd
titanic_train = pd.read_csv('train.csv')
titanic_train.head(20)

titanic_train.info()

titanic_train.duplicated().sum()

titanic_train.columns.duplicated().sum()





"""There are no duplicated rows or columns, so there is no need to use drop_duplicates().

#Exercise 2: Handling Missing Values
Identify columns in the Titanic dataset with missing values.
Explore different strategies for handling missing data, such as removal, imputation, and filling with a constant value.
Apply each strategy to different columns based on the nature of the data.
Hint: Review methods like dropna(), fillna(), and SimpleImputer from scikit-learn.
"""

titanic_train.isnull().sum() #It shows that the columns with missing data are 'Age', 'cabin' and 'Embarked'

#for filling the 'Embarked'

titanic_train['Embarked'].mode()[0]
most_frequent_embarked = titanic_train['Embarked'].mode()[0]
embarked_fill = titanic_train['Embarked'].fillna(most_frequent_embarked)

titanic_train['Embarked'] = embarked_fill
titanic_train.isnull().sum()

#filling the age

titanic_train['Age'].median()

median_age = titanic_train['Age'].median()
age_complete = titanic_train['Age'].fillna(median_age)

titanic_train['Age'] = age_complete
titanic_train.isnull().sum()

#now for the cabin column

titanic_train['Cabin'].isna()

cabin_mask = titanic_train['Cabin'].isna()
titanic_train[cabin_mask]['Survived'].value_counts()

columns_to_drop = ['Cabin']
titanic_train = titanic_train.drop(columns=columns_to_drop)

#we decide to drop the entire Cabin column since there is a lot of missing data that we cannot find or replace by the mean, median or mode

titanic_train.isnull().sum()

"""#Exercise 3: Feature Engineering
Create new features, such as Family Size from SibSp and Parch, and Title extracted from the Name column.

Convert categorical variables into numerical form using techniques like one-hot encoding or label encoding.

You will encode new categorical features (like Title) here, but do not scale numerical features yet â€” that will come after outlier handling.
"""

#starting with the family size

titanic_train['SibSp'] >= 1
sibsp_mask = titanic_train['SibSp'] >= 1

titanic_train['Parch'] >= 1
parch_mask = titanic_train['Parch'] >= 1
family_size = titanic_train[sibsp_mask & parch_mask]

titanic_train['Family Size'] = titanic_train['SibSp'] + titanic_train['Parch'] + 1 #we added the +1 to include the passenger as well
titanic_train['Family Size']

#adding the Title column

titanic_train['Title'] = titanic_train['Name'].str.extract(' ([A-Za-z]+)\.', expand=False)
titanic_train[['Name','Title']]

titanic_train['Name'] = titanic_train['Name'].str.replace(' ([A-Za-z]+)\.', '', regex=True) #here we removed what was added to the Title Column from the Name column
titanic_train[['Name', 'Title']]

"""# Exercise 4: Outlier Detection and Handling
Detect and cap or transform outliers in columns like Fare and Age.


"""

#start with the Fare column

Q1 = titanic_train['Fare'].quantile(0.25)
Q3 = titanic_train['Fare'].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 0.98 * IQR
upper_bound = Q3 + 0.98 * IQR
titanic_train = titanic_train[(titanic_train['Fare'] >= lower_bound) & (titanic_train['Fare'] <= upper_bound)]
titanic_train['Fare'].head()

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(12, 5))

# Histogram for Fare distribution
plt.subplot(1, 2, 1) # 1 row, 2 columns, first plot
sns.histplot(titanic_train['Fare'], kde=True)
plt.title('Distribution of Fare')
plt.xlabel('Fare')
plt.ylabel('Frequency')

# Box plot for Fare to show quartiles and outliers
plt.subplot(1, 2, 2) # 1 row, 2 columns, second plot
sns.boxplot(y=titanic_train['Fare'])
plt.title('Box Plot of Fare')
plt.ylabel('Fare')

plt.tight_layout()
plt.show()

Q1_age = titanic_train['Age'].quantile(0.25)
Q3_age = titanic_train['Age'].quantile(0.75)
IQR_age = Q3_age - Q1_age
lower_bound_age = Q1_age - 1.5 * IQR_age
upper_bound_age = Q3_age + 1.5 * IQR_age

titanic_train = titanic_train[(titanic_train['Age'] >= lower_bound_age) & (titanic_train['Age'] <= upper_bound_age)]
titanic_train.head()

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(12, 5))

# Histogram for Age distribution
plt.subplot(1, 2, 1) # 1 row, 2 columns, first plot
sns.histplot(titanic_train['Age'], kde=True)
plt.title('Distribution of Age')
plt.xlabel('Age')
plt.ylabel('Frequency')

# Box plot for Age to show quartiles and outliers
plt.subplot(1, 2, 2) # 1 row, 2 columns, second plot
sns.boxplot(y=titanic_train['Age'])
plt.title('Box Plot of Age')
plt.ylabel('Age')

plt.tight_layout()
plt.show()

"""#Exercise 5: Data Standardization and Normalization

Use StandardScaler (mean = 0, std = 1) for normally distributed features.
Use MinMaxScaler (range [0, 1]) for features that are skewed or bounded.
"""



from sklearn.preprocessing import StandardScaler

# Initialize the StandardScaler
scaler = StandardScaler()

# Fit the scaler to the 'Fare' column and transform it
# We reshape to (-1, 1) because StandardScaler expects a 2D array (samples, features)
titanic_train['Fare_scaled'] = scaler.fit_transform(titanic_train[['Fare']])

# Display the first few rows with the new scaled 'Fare' column
titanic_train[['Fare', 'Fare_scaled']].head()



"""#Exercise 6: Feature Encoding

1. Identify remaining categorical columns (e.g. Sex, Embarked, Title).

2. Apply:
One-Hot Encoding for nominal variables.
Label Encoding if any ordinal variables remain.

3. Merge encoded columns back into the main dataset.
"""

#one-hot encoding for sex

if 'Sex' in titanic_train.columns:
    sex_encoded = pd.get_dummies(titanic_train['Sex'], prefix='Sex', dtype=int)
    titanic_train = pd.concat([titanic_train, sex_encoded], axis=1)
    titanic_train = titanic_train.drop('Sex', axis=1)
    print("One-hot encoding applied to 'Sex' column and original 'Sex' column dropped.")
else:
    print("'Sex' column not found, assuming it has already been processed or does not exist.")
titanic_train.head()

#one_hot encoding for title

if 'Title' in titanic_train.columns:
    title_encoded = pd.get_dummies(titanic_train['Title'], prefix='Title', dtype=int)
    titanic_train = pd.concat([titanic_train, title_encoded], axis=1)
    titanic_train = titanic_train.drop('Title', axis=1)
    print("One-hot encoding applied to 'Title' column and original 'Title' column dropped.")
else:
    print("'Title' column not found, assuming it has already been processed or does not exist.")
titanic_train.head()

#one-hot encoding for embarked

if 'Embarked' in titanic_train.columns:
    embarked_encoded = pd.get_dummies(titanic_train['Embarked'], prefix='Embarked', dtype=int)
    titanic_train = pd.concat([titanic_train, embarked_encoded], axis=1)
    titanic_train = titanic_train.drop('Embarked', axis=1)
    print("One-hot encoding applied to 'Embarked' column and original 'Embarked' column dropped.")
else:
    print("'Embarked' column not found, assuming it has already been processed or does not exist.")
titanic_train.head()

"""# Exercise 7: Data Transformation for Age Feature
Goal: Create and encode age groups.

Use pd.cut() to create bins for life stages (e.g. child, teen, adult, senior).
Apply one-hot encoding using pd.get_dummies().

"""

bins = [0, 14, 20, 30, 60, 120] # age categories
labels = ['child', 'teen', 'young adult', 'adult', 'senior']

titanic_train['Age Group'] = pd.cut(titanic_train['Age'], bins=bins, labels=labels)
titanic_train.head()