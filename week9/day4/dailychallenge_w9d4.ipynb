{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Daily Challenge: Power Up Your A/B Testing for Your Online Bakery!**\n",
        "\n",
        "\n",
        "Context:\n",
        "\n",
        "The Great Bake-Off\n",
        "You’re the data analyst for a popular online bakery, “Sweet Bytes,” known for its delicious treats and innovative digital marketing campaigns. The bakery is about to launch a new checkout process, and the team believes it could significantly boost sales. However, before making the switch, you need to run an A/B test to ensure the new process truly outperforms the current one. To do this, you’ll need to calculate the right sample size to ensure your test is both efficient and reliable. Ready to power up your A/B testing skills and help Sweet Bytes make the right decision? Let’s dive in!\n",
        "\n"
      ],
      "metadata": {
        "id": "7aEv3uV9h4WH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvSaRH-1h3Fu",
        "outputId": "2a760bd6-0d98-411c-8346-310eee006bf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Required sample size per group: 393.41\n"
          ]
        }
      ],
      "source": [
        "# Calculate the Required Sample Size:\n",
        "# Imagine the current checkout process has a conversion rate of 5%, and the bakery’s team is confident the new process will boost this to 7%.\n",
        "# Use Python to calculate the required sample size per group (current vs. new checkout process) with an effect size of 0.2, a significance level of 0.05, and a desired power of 0.8.\n",
        "\n",
        "from statsmodels.stats.power import TTestIndPower\n",
        "\n",
        "# Set the parameters\n",
        "effect_size = 0.2\n",
        "alpha = 0.05\n",
        "power = 0.8\n",
        "\n",
        "# Calculate the sample size\n",
        "analysis = TTestIndPower()\n",
        "sample_size = analysis.solve_power(effect_size=effect_size, alpha=alpha, power=power)\n",
        "print(f'Required sample size per group: {sample_size:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze the Impact of Effect Size:\n",
        "# The bakery’s head chef, always aiming for perfection, wonders what would happen if the effect size were different. Calculate the required sample size for effect sizes of 0.1, 0.2, 0.3, and 0.4.\n",
        "# Explain how the sample size requirements change as the effect size changes. Why does this happen?\n",
        "\n",
        "# Set the parameters\n",
        "effect_sizes = [0.1, 0.2, 0.3, 0.4] # Changed variable name to avoid confusion\n",
        "alpha = 0.05\n",
        "power = 0.8\n",
        "\n",
        "# Calculate the sample size for each effect size\n",
        "analysis = TTestIndPower()\n",
        "\n",
        "print(\"Required sample sizes per group for different effect sizes:\")\n",
        "for es in effect_sizes:\n",
        "    sample_size = analysis.solve_power(effect_size=es, alpha=alpha, power=power)\n",
        "    print(f'Effect Size: {es:.1f}, Sample Size: {sample_size:.2f}')\n",
        "\n",
        "print(\"\\nExplanation:\\nAs the effect size increases, the required sample size decreases. This is because a larger effect size indicates a stronger difference or relationship between the groups being tested. When the difference is more pronounced, it's easier to detect it with a smaller sample, reducing the number of observations needed to achieve the desired statistical power and significance level. Conversely, if the expected effect size is small, you need a larger sample to reliably detect that subtle difference.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjNkuVAYiWx8",
        "outputId": "f222b881-9b70-4991-a4c4-2e4a82a2f069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Required sample sizes per group for different effect sizes:\n",
            "Effect Size: 0.1, Sample Size: 1570.73\n",
            "Effect Size: 0.2, Sample Size: 393.41\n",
            "Effect Size: 0.3, Sample Size: 175.38\n",
            "Effect Size: 0.4, Sample Size: 99.08\n",
            "\n",
            "Explanation:\n",
            "As the effect size increases, the required sample size decreases. This is because a larger effect size indicates a stronger difference or relationship between the groups being tested. When the difference is more pronounced, it's easier to detect it with a smaller sample, reducing the number of observations needed to achieve the desired statistical power and significance level. Conversely, if the expected effect size is small, you need a larger sample to reliably detect that subtle difference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explain the Relationship:**\n",
        "\n",
        "Imagine you’re explaining this to the bakery’s team in a fun, easy-to-understand way. Why is it so important to balance effect size and sample size when planning an A/B test? Help them understand how this ensures they’re not wasting time or resources and how it helps them confidently make decisions that could increase their sweet sales.\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "Effect size is simply how big the improvement is. Are we hoping the new cookie sells just a tiny bit more, or a lot more? Sample size is how many customers need to taste the cookies. These two things are connected: if the improvement is small (just a few extra sales), you need a lot of customers to be sure it’s real. If the improvement is big (everyone suddenly loves it), you can figure that out with fewer people.\n",
        "\n",
        "Balancing the two is important so you don’t waste time or ingredients. If you test with too few customers, you might think a recipe is better when it’s not—or miss a winner entirely. If you test with way too many customers, you’re spending extra time and money when you already had enough information. Power analysis helps you plan the “just right” number of tasters, so when you choose a recipe, you can be confident it truly helps sell more sweets—and not just because you got lucky that day."
      ],
      "metadata": {
        "id": "nIETkaXljODm"
      }
    }
  ]
}